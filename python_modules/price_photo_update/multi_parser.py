import os
import re
import time
import pandas as pd
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import mysql.connector
from bs4 import BeautifulSoup
import random
import logging


'''
23
'''
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
OUTPUT_DIR = "output"
OUTPUT_FILENAME = "products.xlsx"
OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)
BASE_URL = "https://trast-zapchast.ru"
THREADS = 4  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ç–∞–ª–æ–≥–∞

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –ü—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä—ã
PROXY_LIST = [
    "vpn-uk1.trafflink.xyz:443",
    "vpn-uk2.trafflink.xyz:443",
    "vpn-uk3.trafflink.xyz:443",
    "uk28.trafcfy.com:437",
    "uk27.trafcfy.com:437",
    "uk36.trafcfy.com:437",
]

current_proxy = None  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

def get_random_proxy():
    return random.choice(PROXY_LIST)

def connect_to_db():
    try:
        return mysql.connector.connect(
            host="127.0.0.1",
            user="uploader",
            password="uploader",
            database="avito"
        )
    except mysql.connector.Error as err:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {err}")
        raise

def update_config_status(db_connection, key, value):
    logging.info(f'–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤ –ë–î: {key} -> {value}')
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü–µ config.
    –ï—Å–ª–∏ –∑–∞–ø–∏—Å–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º name –Ω–µ—Ç, –æ–Ω–∞ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞.
    """
    try:
        with db_connection.cursor() as cursor:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–ø–∏—Å—å
            query_check = "SELECT COUNT(*) FROM config WHERE name = %s"
            cursor.execute(query_check, (name,))
            exists = cursor.fetchone()[0]

            if exists:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å
                query_update = "UPDATE config SET value = %s WHERE name = %s"
                cursor.execute(query_update, (value, name))
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                query_insert = "INSERT INTO config (name, value) VALUES (%s, %s)"
                cursor.execute(query_insert, (name, value))

            db_connection.commit()
            logging.info(f"–°—Ç–∞—Ç—É—Å '{name}' —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω –¥–æ –∑–Ω–∞—á–µ–Ω–∏—è '{value}'")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ '{name}' –≤ —Ç–∞–±–ª–∏—Ü–µ config: {e}")
        db_connection.rollback()

# –°–æ–∑–¥–∞–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–æ–∫—Å–∏
def create_driver(proxy):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument(f"--proxy-server=https://{proxy}")
    options.add_argument("--log-level=3")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    logging.info(f'–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–∫—Å–∏: {proxy}')
    return driver

# –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–∫—Å–∏
def get_total_pages():
    global current_proxy
    proxy = get_random_proxy()
    driver = create_driver(proxy)
    driver.get(f"{BASE_URL}/shop/page/1")
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    pagination = soup.select('ul.page-numbers li')
    driver.quit()
    
    total_pages = int(pagination[-2].get_text(strip=True)) if pagination else 1
    current_proxy = proxy if total_pages > 1 else get_random_proxy()
    logging.info(f'–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ {current_proxy} –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.')
    return total_pages

def parse_page(page_number):
    driver = create_driver(current_proxy)
    driver.get(f"{BASE_URL}/shop/page/{page_number}")
    time.sleep(2)
    
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    products = soup.find_all('div', class_='th-product-card')
    
    items = []
    for product in products:
        if product.find('span', class_='out-of-stock'):
            continue
        
        try:
            name = product.find('div', class_='th-product-card__name').find('h2').get_text(strip=True)
            price = re.sub(r'[^\d]', '', product.find('span', class_='woocommerce-Price-amount').get_text(strip=True))
            article = re.sub(r'[\s\-]', '', product.find('span', class_='th-product-card__meta-value').get_text(strip=True))
            image_url = product.find('div', class_='th-product-card__image').find('img')['src']
            product_page_link = product.find('a', class_='woocommerce-LoopProduct-link')['href']
            manufacturer = "–ù/–î"
            items.append({'–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': name, '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å': manufacturer, '–ê—Ä—Ç–∏–∫—É–ª': article, '–¶–µ–Ω–∞': price, '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ': image_url, '–°—Å—ã–ª–∫–∞': product_page_link})
        except Exception as e:
            logging.warning(f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number}: {e}')
            continue
    
    driver.quit()
    logging.info(f'üìÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}')
    return items

def main():
    try:
        with connect_to_db() as db_connection:
            update_config_status(db_connection, "parser_status", "in_progress")
            os.makedirs(OUTPUT_DIR, exist_ok=True)
            if os.path.exists(OUTPUT_PATH):
                os.remove(OUTPUT_PATH)
            
            start_time = datetime.now()
            logging.info(f'‚è≥ –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {start_time.strftime("%Y-%m-%d %H:%M:%S")}')
            total_pages = get_total_pages()
            logging.info(f'üîç –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}')
            
            all_items = []
            with ThreadPoolExecutor(max_workers=THREADS) as executor:
                future_to_page = {executor.submit(parse_page, page): page for page in range(1, total_pages + 1)}
                for future in as_completed(future_to_page):
                    page_number = future_to_page[future]
                    try:
                        items = future.result()
                        all_items.extend(items)
                        logging.info(f'‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞.')
                    except Exception as e:
                        logging.warning(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}')
            
            df = pd.DataFrame(all_items, columns=['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', '–ê—Ä—Ç–∏–∫—É–ª', '–¶–µ–Ω–∞', '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', '–°—Å—ã–ª–∫–∞'])
            df.to_excel(OUTPUT_PATH, sheet_name='–¢–æ–≤–∞—Ä—ã', index=False)
            
            end_time = datetime.now()
            elapsed_time = end_time - start_time
            logging.info(f'‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω! –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_items)}')
            logging.info(f'üìÇ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUTPUT_PATH}')
            logging.info(f'‚è≥ –ö–æ–Ω–µ—Ü: {end_time.strftime("%Y-%m-%d %H:%M:%S")}')
            logging.info(f'‚è± –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {elapsed_time}')
            update_config_status(db_connection, "parser_status", "done")
            update_config_status(db_connection, "parser_update_time", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        update_config_status(db_connection, "parser_status", "failed")
        update_config_status(db_connection, "parser_update_time", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

if __name__ == '__main__':
    main()
